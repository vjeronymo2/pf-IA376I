{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e9f2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import re\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea6d9407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(path):\n",
    "    print('Loading corpus...')\n",
    "    corpus = {}\n",
    "    n_text = 0\n",
    "    with open(path, errors='ignore') as f:\n",
    "        all_text = ' '.join(f.read().split())\n",
    "        for raw_text in tqdm(all_text.split('</DOC>')):\n",
    "            if not raw_text:\n",
    "                continue\n",
    "            result = re.search(r'\\<DOCNO\\>(.*)\\<\\/DOCNO\\>', raw_text)\n",
    "            if not result:\n",
    "                continue\n",
    "            doc_id = result.group(1)\n",
    "            doc_id = doc_id.strip()\n",
    "\n",
    "            result = re.search(r'\\<TEXT\\>(.*)\\<\\/TEXT\\>', raw_text)\n",
    "            doc_text = ''\n",
    "            if result:\n",
    "                doc_text = result.group(1)\n",
    "                doc_text = BeautifulSoup(doc_text, 'html.parser').text\n",
    "                doc_text = doc_text.strip()\n",
    "                if doc_text:\n",
    "                    n_text += 1\n",
    "\n",
    "            corpus[doc_id] = ' '.join(doc_text.split())\n",
    "\n",
    "    print(f'Loaded {len(corpus)} docs, {n_text} with texts.')\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0262c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(path):\n",
    "    print('Loading corpus...')\n",
    "    corpus = {}\n",
    "    n_text = 0\n",
    "    with open(path, errors='ignore') as f:\n",
    "        all_text = ' '.join(f.read().split())\n",
    "        for raw_text in tqdm(all_text.split('</DOC>')):\n",
    "            if not raw_text:\n",
    "                continue\n",
    "            result = re.search(r'\\<DOCNO\\>(.*)\\<\\/DOCNO\\>', raw_text)\n",
    "            if not result:\n",
    "                continue\n",
    "            doc_id = result.group(1)\n",
    "            doc_id = doc_id.strip()\n",
    "\n",
    "            result = re.search(r'\\<TEXT\\>(.*)\\<\\/TEXT\\>', raw_text)\n",
    "            doc_text = ''\n",
    "            if result:\n",
    "                doc_text = result.group(1)\n",
    "                doc_text = doc_text.replace('<P>', ' ').replace('</P>', ' ')\n",
    "                doc_text = doc_text.strip()\n",
    "                if doc_text:\n",
    "                    n_text += 1\n",
    "\n",
    "            corpus[doc_id] = ' '.join(doc_text.split())\n",
    "\n",
    "    print(f'Loaded {len(corpus)} docs, {n_text} with texts.')\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01b6107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 528160/528160 [00:58<00:00, 8980.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 528156 docs, 523869 with texts.\n"
     ]
    }
   ],
   "source": [
    "corpus = load_corpus('repos/pygaggle/data/robust04/trec_disks_4_and_5_concat.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff5bf2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('repos/pygaggle/data/robust04/run.robust04.bm25.txt', sep=' ', header=None)\n",
    "bm25_docs = df.iloc[:,2].to_list()\n",
    "empty_docs = [i for i in corpus.keys() if corpus[i]=='']\n",
    "len([i for i in empty_docs if i in bm25_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a17b6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "doc_id = list(corpus.keys())[np.random.randint(len(corpus.keys()))]\n",
    "doc_text = corpus[doc_id]\n",
    "soup = BeautifulSoup(doc_text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f55008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Net asset value of London and St Lawrence Investment stood at 138.24p at February 29, down from 140.02p a year earlier. Net revenue for the six months to end-February amounted to Pounds 520,684 (Pounds 493,338) for earnings of 2.74p (2.6p) per share.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32c988ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FR940817-2-00063'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3824972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['FBIS3-20511']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7d5d4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FT923-8736',\n",
       " 'FT923-8742',\n",
       " 'FT923-8784',\n",
       " 'FT923-8838',\n",
       " 'FT923-8875',\n",
       " 'FT923-8885',\n",
       " 'FT923-8892',\n",
       " 'FT923-8976',\n",
       " 'FT923-8980',\n",
       " 'FT923-9005']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key for key, value in corpus.items() if '---------------' in value][7000:7010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(corpus[i]+'\\n\\n\\n\\n\\n') for i in [key for key, value in corpus.items() if '---------------' in value][:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d30ebf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-------------------------------- COMPANIES IN THIS ISSUE -------------------------------- UK Allied Breweries 36 BTR 31 Brent Walker 36 Cable & Wireless 17 Forte 36 Framgord 32 GKN 32 GRE 29 Greencore 32 Hammerson 36 ICI 30 Maple Leaf Inns 36 National Breakdown 32 Relica Food 32 Savoy Hotel 36 Scottish Equitable 32 Shell 32 TIP Europe 30 Tiphook 30 Overseas ABB 30 Alcatel Alsthom 30 Candy 30 Carlsberg 32 EDS 36 Fiat 8 Fininvest 31 Finmeccania 32 GSI 32 General Motors 36 Goldman Sachs 37 Heineken 30 Interbrew 31 KLM 30 Labatt 36 MBP Software 36 Max Mara 32 McDonalds 8 Monsanto Europe 32 Peoples Jewellers 37 Peugoet 30 Renault 8 Siemens 32 Solvay 31 Sony Europe 30 Viscofan 30 Volkswagen 8 Wurttembergische 32 --------------------------------'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeautifulSoup(corpus['FT931-16924'], 'html.parser').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0518cb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
